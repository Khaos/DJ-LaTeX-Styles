%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Dazhi Jiang at 2011-09-27 00:09:27 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{ICA:theis2003mathematics,
	Author = {Fabian J. Theis},
	Booktitle = {Signal Processing and Its Applications, 2003. Proceedings. Seventh International Symposium on},
	Date-Added = {2011-09-26 18:36:58 +0100},
	Date-Modified = {2011-09-26 18:55:51 +0100},
	Keywords = {independent component analysis},
	Organization = {IEEE},
	Pages = {609--610},
	Title = {Mathematics in independent component analysis},
	Volume = {2},
	Year = {2003}}

@book{ICA:theis2002mathematics-thesis,
	Address = {Berlin},
	Author = {Fabian J. Theis},
	Date-Added = {2011-09-26 18:27:56 +0100},
	Date-Modified = {2011-09-26 18:58:43 +0100},
	Keywords = {independent component analysis},
	Publisher = {Logos Verlag},
	Title = {Mathematics in Independent Component Analysis},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAqgAAAAAAqgAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMfUpeFIKwAABN24Jx97VH1bTWF0aGVtYXRpY3MgaW4gIzREREI2NDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE3bZEyqIYmyBGRFBPUkFDAAUABQAACSAAAAAAAAAAAAAAAAAAAAAPRmFiaWFuIEouIFRoZWlzAAAQAAgAAMfUl9EAAAARAAgAAMqiCosAAAABACAE3bgnBN24HgAbB1gAGwcsABK14QAStd8ACEuNAACS8wACAH1NYWNpbnRvc2ggSEQ6VXNlcnM6S2hhb3M6aURvY3M6aVJlc2VhcmNoOjAwMExpdGVyYXR1cmU6MDI1IC0gQlNTICYgSUNBOlRoZXNpczpGYWJpYW4gSi4gVGhlaXM6e1R9W01hdGhlbWF0aWNzIGluICM0RERCNjQ0LnBkZgAADgB8AD0AewBUAH0AWwBNAGEAdABoAGUAbQBhAHQAaQBjAHMAIABpAG4AIABJAG4AZABlAHAAZQBuAGQAZQBuAHQAIABDAG8AbQBwAG8AbgBlAG4AdAAgAEEAbgBhAGwAeQBzAGkAcwAgACgAMgAwADAAMgApAF0ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAI5Vc2Vycy9LaGFvcy9pRG9jcy9pUmVzZWFyY2gvMDAwTGl0ZXJhdHVyZS8wMjUgLSBCU1MgJiBJQ0EvVGhlc2lzL0ZhYmlhbiBKLiBUaGVpcy97VH1bTWF0aGVtYXRpY3MgaW4gSW5kZXBlbmRlbnQgQ29tcG9uZW50IEFuYWx5c2lzICgyMDAyKV0ucGRmABMAAS8AABUAAgAM//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEIEuLi8uLi8uLi8uLi8uLi8wMDBMaXRlcmF0dXJlLzAyNSAtIEJTUyAmIElDQS9UaGVzaXMvRmFiaWFuIEouIFRoZWlzL3tUfVtNYXRoZW1hdGljcyBpbiBJbmRlcGVuZGVudCBDb21wb25lbnQgQW5hbHlzaXMgKDIwMDIpXS5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKADTANOA1MDXANnA2sDeQOAA4kEDQQSBBUEIgQnAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABDk=}}

@inproceedings{ICA:herault1986space,
	Author = {Herault, J. and Jutten, C.},
	Booktitle = {AIP conference proceedings},
	Date-Added = {2011-09-26 18:11:18 +0100},
	Date-Modified = {2011-09-26 18:14:46 +0100},
	Keywords = {independent component analysis},
	Pages = {206},
	Title = {Space or time adaptive signal processing by neural network models},
	Volume = {151},
	Year = {1986}}

@article{PCA:Bakshi1998MSPCA,
	Author = {Bakshi, B. R.},
	Date-Added = {2011-09-05 19:33:36 +0100},
	Date-Modified = {2011-09-26 18:40:14 +0100},
	Journal = {American Institute of Chemical Engineers Journal},
	Keywords = {principal component analysis},
	Number = {7},
	Pages = {1596-1610},
	Title = {Multiscale {PCA} with application to multivariate statistical process monitoring},
	Volume = {44},
	Year = {1998}}

@misc{PCA:Emigholz2006AssumptionsPatent,
	Author = {Emigholz, Kenneth F. and McLain, Richard B. and Wang, Robert K. and Woo, Stephen S.},
	Date-Added = {2011-09-05 19:33:36 +0100},
	Date-Modified = {2011-09-26 18:40:14 +0100},
	Keywords = {principal component analysis},
	Number = {20060074599},
	Title = {Application of abnormal event detection technology to olefins recovery trains},
	Url = {http://www.freepatentsonline.com/20060074599.html},
	Year = {2006},
	Bdsk-Url-1 = {http://www.freepatentsonline.com/20060074599.html}}

@article{PCA:Li2000AdaptivePCA,
	Author = {Li, Weihua and Yue, H. Henry and Valle-Cervantes, Sergio and Qin, S. Joe},
	Date-Added = {2011-09-05 19:33:36 +0100},
	Date-Modified = {2011-09-26 18:40:01 +0100},
	Journal = {Journal of Process Control},
	Keywords = {principal component analysis},
	Number = {5},
	Pages = {471-486},
	Title = {Recursive {PCA} for adaptive process monitoring},
	Volume = {10},
	Year = {2000}}

@article{FDI:Venkatasubramanian2003ReviewII,
	Author = {Venkatasubramanian, V. and Rengaswamy, R. and Kavuri, S. N.},
	Date-Added = {2011-09-05 19:32:05 +0100},
	Date-Modified = {2011-09-05 19:32:05 +0100},
	Journal = {Computers and Chemical Engineering},
	Number = {3},
	Pages = {313-326},
	Title = {A review of process fault detection and diagnosis {P}art {II}: {Q}uantitative model and search strategies},
	Volume = {27},
	Year = {2003}}

@article{FDI:Venkatasubramanian2003ReviewIII,
	Author = {Venkatasubramanian, V. and Rengaswamy, R. and Kavuri, S. N. and Yin, K.},
	Date-Added = {2011-09-05 19:32:05 +0100},
	Date-Modified = {2011-09-05 19:32:05 +0100},
	Journal = {Computers and Chemical Engineering},
	Number = {3},
	Pages = {327-346},
	Title = {A review of process fault detection and diagnosis {P}art {III}: {P}rocess history based methods},
	Volume = {27},
	Year = {2003}}

@phdthesis{FDI:Yang2004FaultDiagnosis,
	Author = {Yang, Qingsong},
	Date-Added = {2011-09-05 19:32:05 +0100},
	Date-Modified = {2011-09-05 19:32:05 +0100},
	School = {Case Western Reserve University},
	Title = {Model-based and data driven fault diagnosis methods with applications to process monitoring},
	Year = {2004}}

@article{FDI:Venkatasubramanian2003ReviewI,
	Author = {Venkatsubramanian, V. and Rengaswamy, R. and Yin, K. and Kavuri, S. N.},
	Date-Added = {2011-09-05 19:31:56 +0100},
	Date-Modified = {2011-09-05 19:31:56 +0100},
	Journal = {Computers and Chemical Engineering},
	Number = {3},
	Pages = {293-311},
	Title = {A review of process fault detection and diagnosis {P}art {I}: {Q}uantitative model-based methods},
	Volume = {27},
	Year = {2003}}

@article{PCA:Wise1990TheoreticalBasis,
	Author = {Wise, B. M. and Ricker, N. L. and Veltkamp, D. J. and Kowalski, B. R.},
	Date-Added = {2011-09-05 19:30:21 +0100},
	Date-Modified = {2011-09-26 18:40:14 +0100},
	Journal = {Process Control and Quality},
	Keywords = {principal component analysis},
	Number = {1},
	Pages = {41-51},
	Title = {A Theoretical Basis for the Use of Principal Components Models for Monitoring Multivariate Processes},
	Volume = {1},
	Year = {1990}}

@incollection{LevyFun:Levy1982Topics,
	Abstract = {A summary of the reserch done in global optimization at the Numerical
	Analysis Departament of IIMAS-UNAM is given. The concept of the Tunnelling
	Function and the key ideas of the Tunnelling Algorithm as applied
	to Unconstrained Global Optimization, Stabilization of Newton's Method
	and Constrained Global Optimization are presented. Numerical results
	for several examples are given, they have from one to ten variables
	and from three to several thousands of local minima, clearly illustrating
	the robustness of the Tunnelling Algorithm.},
	Author = {Levy, A. and Montalvo, A. and Gomez, S. and Calderon, A.},
	Booktitle = {Numerical Analysis},
	Date-Added = {2011-06-14 17:50:42 +0100},
	Date-Modified = {2011-06-14 17:50:42 +0100},
	Pages = {18-33},
	Publisher = {Springer},
	Title = {Topics in global optimization},
	Year = {1982}}

@inproceedings{ICA:comon1992independent,
	Author = {Comon, P.},
	Booktitle = {Republished in Higher-Order Statistics},
	Date-Added = {2011-05-26 12:19:16 +0100},
	Date-Modified = {2011-09-26 18:14:46 +0100},
	Editor = {J. L. Lacoume},
	Keywords = {independent component analysis},
	Pages = {29--38},
	Publisher = {Elsevier},
	Title = {Independent component analysis},
	Year = {1992}}

@article{ICA:comon1994independent,
	Author = {Comon, P.},
	Date-Added = {2011-05-26 11:59:51 +0100},
	Date-Modified = {2011-09-26 18:14:46 +0100},
	Journal = {Signal processing},
	Keywords = {independent component analysis},
	Number = {3},
	Pages = {287--314},
	Publisher = {Elsevier},
	Title = {Independent component analysis, a new concept?},
	Volume = {36},
	Year = {1994}}

@book{ICA:Comon:2010:HBS:1841191,
	Author = {Comon, Pierre and Jutten, Christian},
	Date-Added = {2011-05-24 15:49:50 +0100},
	Date-Modified = {2011-09-26 19:56:07 +0100},
	Editor = {Comon, Pierre and Jutten, Christian},
	Isbn = {0123747260, 9780123747266},
	Keywords = {blind source separation, independent component analysis},
	Publisher = {Academic Press},
	Title = {Handbook of Blind Source Separation: Independent Component Analysis and Applications},
	Year = {2010}}

@inproceedings{NDT:Abu-el-zeet2006FleetWide,
	Address = {Glasgow, UK},
	Author = {{Abu-el-zeet}, Z. H. and Patel, V. C.},
	Booktitle = {UKACC International Control 2006 conference},
	Title = {Application of novelty detection for fleet-wide monitoring of power plants},
	Year = {August 2006}}

@inproceedings{NDT:Abu-el-zeet2006PowerPlant,
	Address = {Coventry, UK},
	Author = {{Abu-el-zeet}, Z. H. and Patel, V. C.},
	Booktitle = {Proceedings of the Eighteenth International Conference on Systems Engineering (ICSE2006)},
	Editor = {Burnham, K. J. and Haas, O. C. L.},
	Title = {Power plant condition monitoring using novelty detection},
	Year = {September 2006}}

@techreport{NDT:Abu-el-zeet2002ALSTOM01,
	Author = {{Abu-el-zeet}, Z. H. and Patel, V. C. and Knight, P. H.},
	Number = {{ALSTOM Report No. Z31438}},
	Title = {Post-processing improvements to the Novelty Detection Tool},
	Year = {2002}}

@techreport{PCA:Abu-el-zeet2001Investigation,
	Author = {Abu-{el-zeet}, Z. H. and Patel, V. C.},
	Month = {April},
	Title = {Investigation and Development of Data-Driven Methods},
	Type = {Internal report no. {B}21929/3},
	Year = {2001}}

@article{AD:Agyemang2006SurveyOfOutlierMining,
	Abstract = {Data that appear to have different characteristics than the rest of the population are called outliers. Identifying outliers from huge data repositories is a very complex task called outlier mining. Outlier mining has been akin to finding needles in a haystack. However, outlier mining has a number of practical applications in areas such as fraud detection, network intrusion detection, and identification of competitor and emerging business trends in e-commerce. This survey discuses practical applications of outlier mining, and provides a taxonomy for categorizing related mining techniques. A comprehensive review of these techniques with their advantages and disadvantages along with some current research issues are provided.},
	Author = {Agyemang, M. and Barker, K. and Alhajj, R.},
	Journal = {Intelligent Data Analysis},
	Keywords = {symbolic rule-based distance-based depth-based distribution-based outliers interestingness unexpectedness taxonomy web-based exception patterns knowledge discovery local outliers algorithms database systems},
	Number = {6},
	Pages = {521-538},
	Title = {A comprehensive survey of numeric and symbolic outlier mining techniques},
	Volume = {10},
	Year = {2006}}

@article{AD4PP:Arranz2008DADICC,
	Abstract = {DADICC is the abbreviated name for an intelligent system able to detect on-line and diagnose anomalies as soon as possible in the dynamic evolution of the behaviour of a power plant based on a combined cycle gas turbine. In order to reach this objective, a modelling process is required for the characterization of the normal performance when any symptom of a possible fault is present. This will be the reference for early detection of possible anomalies. If a deviation in respect to the normal behaviour predicted is observed, an analysis of its causes is performed in order to diagnose the potential problem, and, if possible, its prevention. A multi-agent system supports the different roles required in DADICC. The detection of anomalies is based on agents that use models elaborated using mainly neural networks techniques. The diagnosis of the anomalies is prepared by agents based on an expert-system structure. This paper describes the main characteristics of DADICC and its operation. (c) 2007 Elsevier Ltd. All rights reserved.},
	Author = {Arranz, A. and Cruz, A. and Sanz-Bobi, M. A. and Ruiz, P. and Coutino, J.},
	Journal = {Expert Systems with Applications},
	Keywords = {anomaly detection normal behaviour diagnosis multi-agent system neural network expert system},
	Number = {4},
	Pages = {2267-2277},
	Title = {DADICC: Intelligent system for anomaly detection in a combined cycle gas turbine plant},
	Volume = {34},
	Year = {2008}}

@inproceedings{FD:Arriagada2003FaultDiagnosis,
	Address = {Tokyo},
	Author = {Arriagada, J and Genrup, M and Loberg, A and Assadi, M},
	Booktitle = {Proceedings of the International Gas Turbine Congress 2003},
	Title = {Fault diagnosis system for an industrial gas turbine by means of neural networks},
	Year = {2003}}

@inproceedings{AD:Bakar2006StydyForOD,
	Abstract = {Existing studies in data mining mostly focus on finding patterns in large datasets and further using it for organizational decision making. However, finding such exceptions and outliers has not yet received as much attention in the data mining field as some other topics have, such as association rules, classification and clustering. Thus, this paper describes the performance of control chart, linear regression, and Manhattan distance techniques for outlier detection in data mining. Experimental studies show that outlier detection technique using control chart is better than the technique modeled from linear regression because the number of outlier data detected by control chart is smaller than linear regression. Further, experimental studies shows that Manhattan distance technique outperformed compared with the other techniques when the threshold values increased},
	Author = {Bakar, Z. A. and Mohemad, R. and Ahmad, A. and Deris, M. M.},
	Booktitle = {Cybernetics and Intelligent Systems, 2006 IEEE Conference on},
	Keywords = {data mining regression analysis Manhattan distance performance control chart performance linear regression performance outlier detection clustering outlier},
	Pages = {1-6},
	Title = {A Comparative Study for Outlier Detection Techniques in Data Mining},
	Year = {2006}}

@article{AD:Beckman1983Outliers,
	Author = {Beckman, R. J. and Cook, R. D.},
	Date-Modified = {2011-09-06 17:13:11 +0100},
	Journal = {Technometrics},
	Keywords = {anomaly detection},
	Number = {2},
	Pages = {119-149},
	Title = {Outliers},
	Volume = {25},
	Year = {1983}}

@article{AD:Bishop1994ND4NN,
	Abstract = {One of the key factors which limits the use of neural networks in many industrial applications has been the difficulty of demonstrating that a trained network will continue to generate reliable outputs once it is in routine use. An important potential source of errors is novel input data; that is, input data which differ significantly from the data used to train the network. The author investigates the relationship between the degree of novelty of input data and the corresponding reliability of the outputs from the network. He describes a quantitative procedure for assessing novelty, and demonstrates its performance by using an application which involves monitoring oil flow in multiphase pipelines.},
	Author = {Bishop, C. M.},
	Journal = {Iee Proceedings-Vision Image and Signal Processing},
	Keywords = {novelty assessment neural networks},
	Number = {4},
	Pages = {217-222},
	Title = {Novelty Detection and Neural-Network Validation},
	Volume = {141},
	Year = {1994}}

@techreport{KDE:Botev2005Stochasitc,
	Author = {Botev, Z. I.},
	Date-Modified = {2011-09-06 17:14:03 +0100},
	Keywords = {KDE},
	Title = {Stochastic Methods for Optimization and Machine Learning},
	Type = {Technical Report},
	Year = {2005}}

@techreport{KDE-GCE:Botev2006Novel,
	Author = {Botev, Z. I.},
	Institution = {Mathematics (School of Physical Sciences), The University of Queensland},
	Month = {Nov 12},
	Title = {A Novel Nonparametric Density Estimator},
	Type = {Postgraduate Seminar Series},
	Year = {2006}}

@misc{KDE-GCE:Botev2007GCEwithApplicationtoKDE,
	Author = {Botev, Z. I. and Kroese, D. P.},
	Keywords = {cross entropy information theory kernel smoothing bandwidth selection},
	Month = {Feb 1},
	Publisher = {The University of Queensland},
	Title = {The Generalized Cross Entropy Method, with Applications to Probability Density Estimation},
	Url = {http://espace.library.uq.edu.au/view.php?pid=UQ:12759},
	Year = {2007},
	Bdsk-Url-1 = {http://espace.library.uq.edu.au/view.php?pid=UQ:12759}}

@article{KDE-GCE:Botev2008RareEvents,
	Abstract = {Although importance sampling is an established and effective sampling and estimation technique, it becomes unstable and unreliable for high-dimensional problems. The main reason is that the likelihood ratio in the importance sampling estimator degenerates when the dimension of the problem becomes large. Various remedies to this problem have been suggested, including heuristics such as resampling. Even so, the consensus is that for large-dimensional problems, likelihood ratios (and hence importance sampling) should be avoided. In this paper we introduce a new adaptive simulation approach that does away with likelihood ratios, while retaining the multi-level approach of the cross-entropy method. Like the latter, the method can be used for rare-event probability estimation, optimization, and counting. Moreover, the method allows one to sample exactly from the target distribution rather than asymptotically as in Markov chain Monte Carlo. Numerical examples demonstrate the effectiveness of the method for a variety of applications.},
	Author = {Botev, Z. I. and Kroese, D. P.},
	Journal = {Methodology and Computing in Applied Probability},
	Keywords = {likelihood ratio degeneracy kernel density estimation importance sampling exact sampling rare-event probability estimation combinatorial counting cross-entropy method},
	Number = {4},
	Pages = {471-505},
	Title = {An efficient algorithm for rare-event probability estimation, combinatorial optimization, and counting},
	Volume = {10},
	Year = {2008}}

@article{KDE-GCE:Botev2008NonAsymptotic,
	Abstract = {We propose a new method for density estimation of categorical data. The method implements a non-asymptotic data-driven bandwidth selection rule and provides model sparsity not present in the standard kernel density estimation method. Numerical experiments with a well-known ten-dimensional binary medical data set illustrate the effectiveness of the proposed approach for density estimation, discriminant analysis and classification.},
	Author = {Botev, Z. I. and Kroese, D. P.},
	Journal = {Methodology and Computing in Applied Probability},
	Keywords = {bandwidth selection kernel density estimator generalized cross entropy statistical modeling discrete data smoothing multivariate binary discrimination multivariate binary discrimination categorical-data kernel},
	Number = {3},
	Pages = {435-451},
	Title = {Non-asymptotic bandwidth selection for density estimation of discrete data},
	Volume = {10},
	Year = {2008}}

@article{AD4PP:Brown2007LearningModels,
	Abstract = {Providing engineers and asset managers with a too] which can diagnose faults within transformers can greatly assist decision making on such issues as maintenance, performance and safety. However, the onus has always been on personnel to accurately decide how serious a problem is and how urgently maintenance is required. In dealing with the large volumes of data involved, it is possible that faults may not be noticed until serious damage has occurred. This paper proposes the integration of a newly developed anomaly detection technique with an existing diagnosis system. By learning a Hidden Markov Model of healthy transformer behavior, unexpected operation, such as when a fault develops, can be flagged for attention. Faults can then be diagnosed using the existing system and maintenance scheduled as required, all at a much earlier stage than would previously have been possible.},
	Author = {Brown, A. J. and Catterson, V. M. and Fox, M. and Long, D. and McArthur, S. D. J.},
	Journal = {Engineering Intelligent Systems for Electrical Engineering and Communications},
	Keywords = {cooperative systems decision support systems hidden markov models intelligent systems learning systems monitoring partial discharges power systems power transformers hidden markov-models algorithm system},
	Number = {2},
	Pages = {61-67},
	Title = {Learning models of plant behavior for anomaly detection and condition monitoring},
	Volume = {15},
	Year = {2007}}

@article{SA:Cerny1985Thermodynamical,
	Author = {Cerny, V.},
	Journal = {Journal of Optimization Theory and Applications},
	Number = {1},
	Pages = {41-51},
	Title = {Thermodynamical Approach to the Traveling Salesman Problem - an Efficient Simulation Algorithm},
	Volume = {45},
	Year = {1985}}

@article{AD:Chandola2009ADSurvey,
	Abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
	Author = {Chandola, V. and Banerjee, A. and Kumar, V.},
	Journal = {Acm Computing Surveys},
	Keywords = {algorithms anomaly detection outlier detection unsupervised outlier detection distance-based outliers novelty detection neural-network time-series intrusion-detection density-estimation multivariate data sensor networks local outliers},
	Number = {3},
	Pages = {-},
	Title = {Anomaly Detection: A Survey},
	Volume = {41},
	Year = {2009}}

@article{PCAKDE:Chen2000PCAKDE4FD,
	Abstract = {This paper discusses the application of kernel density estimation (KDE) and principal component analysis (PCA) to provide enhanced monitoring of multivariate processes. Different KDE algorithms are studied and assessed in depth in the context of practical applications so that one bandwidth selection algorithm is recommended for process monitoring. The results of the case studies clearly demonstrate the power and advantages of the KDE approach over parametric density estimation which is still widely used. Statistical summary charts are suggested to raise early warning of faults and locate the physical variables which are the prime indicators of the faults. (C) 2000 Elsevier Science Ltd. All rights reserved.},
	Author = {Chen, Q. and Wynne, R. J. and Goulding, P. and Sandoz, D.},
	Journal = {Control Engineering Practice},
	Keywords = {multivariate processes principal component analysis kernel density estimation process monitoring},
	Number = {5},
	Pages = {531-543},
	Title = {The application of principal component analysis and kernel density estimation to enhance process monitoring},
	Volume = {8},
	Year = {2000}}

@book{FDD:Chiang2001FaultDetection,
	Abstract = {<P>The appearance of this book is quite timely as it provides a much needed state-of-the-art exposition on fault detection and diagnosis, a topic of much interest to industrialists. The material included is well organized with logical and clearly identified parts; the list of references is quite comprehensive and will be of interest to readers who wish to explore a particular subject in depth.</P> <P>The presentation of the subject material is clear and concise, and the contents are appropriate to postgraduate engineering students, researchers and industrialists alike. The end-of-chapter homework problems are a welcome feature as they provide opportunities for learners to reinforce what they learn by applying theory to problems, many of which are taken from realistic situations.</P> <P>However, it is felt that the book would be more useful, especially to practitioners of fault detection and diagnosis, if a short chapter on background statistical techniques were provided.</P> <P><B>Joe Au</B></P>},
	Address = {London},
	Author = {Chiang, L. H. and Russell, E. L. and Braatz, R. D.},
	Publisher = {Springer--Verlag},
	Series = {Advanced Textbooks in Control and Signal Processing},
	Title = {Fault detection and diagnosis in industrial systems},
	Year = {2001}}

@article{ICA:Jutten1991BSSII,
	Abstract = {Though it arouses more and more curiosity, the HJ iterative algorithm has never been derived in mathematical terms to date.  We attempt in this paper to describe it from a statistical point of view.  For instance the updating term of the synaptic efficacies matrix cannot be the gradient of a single C2 functional contrary to what is sometimes understood.  In fact, we show that the HJ algorithm is actually searching common zeros of n functionals by pipelined stochastic iterations.  Based on simulation results, advantages and limitations as well as possible improvements are pointed out after a short theoretical analysis.},
	Author = {Comon, P. and Jutten, C. and Herault, J.},
	Journal = {Signal Processing},
	Keywords = {signal and image processing stochastic processes mixture neural networks principal components independent components inverse problem},
	Number = {1},
	Pages = {11-20},
	Title = {Blind Separation of Sources .2. Problems Statement},
	Volume = {24},
	Year = {1991}}

@article{RobustStatistics:Daszykowski2007,
	Abstract = {Presence of outliers in chemical data affects all least squares models, which are extensively used in chemometrics for data exploration and modeling. Therefore, more and more attention is paid to the so-called robust models and robust statistics that aim to construct models and estimates describing well data majority. Moreover, construction of robust models allows identifying outlying observations. The outliers identification is not only essential for a proper modeling but also for understanding the reasons for unique character of the outlying sample. In this paper some basic concepts of robust techniques are presented and their usefulness in chemometric data analysis is stressed. (c) 2006 Elsevier B.V. All rights reserved.},
	Author = {Daszykowski, M. and Kaczmarek, K. and Heyden, Y. V. and Walczak, B.},
	Journal = {Chemometrics and Intelligent Laboratory Systems},
	Keywords = {outliers l1-median projection pursuit robust covariance mahalanobis distance outlier diagnostic robust pca principal component analysis projection-pursuit approach dispersion matrices squares regression outlier detection covariance estimators efficiency algorithm parafac2},
	Number = {2},
	Pages = {203-219},
	Title = {Robust statistics in data analysis - A review basic concepts},
	Volume = {85},
	Year = {2007}}

@article{KM-PCA:Ding2004K-means,
	Abstract = {K-means Clustering is a popular data clustering algorithm. Principal component analysis (PCA) is a widely used statistical technique for dimension reduction. Here we prove that principal components are the continuous solutions to the discrete cluster membership indicators for K-means clustering, with a clear simplex cluster strcuture. Our results prove that PCA-based dimension reductions are particularlly effective for for K-means clustering. New lower bounds for K-means objective function are derived, which is the total variance minus the eigenvalues of the data covariance matrix.},
	Author = {Ding, C. and He, X. F.},
	Journal = {Advances in Knowledge Discovery and Data Mining, Proceedings},
	Pages = {414-418},
	Title = {Cluster structure of {$K$}-means clustering via principal component analysis},
	Volume = {3056},
	Year = {2004}}

@article{AP:Frey2007Clustering,
	Abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such "exemplars" can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called "affinity propagation," which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
	Author = {Frey, B. J. and Dueck, D.},
	Journal = {Science},
	Keywords = {algorithm codes},
	Number = {5814},
	Pages = {972-976},
	Title = {Clustering by passing messages between data points},
	Volume = {315},
	Year = {2007}}

@article{FDI:Gupta2008FDIInAGTA,
	Abstract = {Degradation monitoring is of paramount importance to safety and reliability of aircraft operations and also for timely maintenance of its critical components. This two-part paper formulates and validates a novel methodology of degradation monitoring of aircraft gas turbine engines with emphasis on detection and isolation of incipient faults. In a complex system with multiple interconnected components (e.g. an aircraft engine), fault isolation becomes a crucial task because of possible input-output and feedback interactions among the individual components.
This paper, which is the first of two parts, presents the underlying concepts of fault detection and isolation (FDI) in complex dynamical systems. The FDI algorithms are formulated in the setting of symbolic dynamic filtering (SDF) that has been recently reported in literature. The underlying concept of SDF is built upon the principles of symbolic dynamics, statistical pattern recognition, and information theory. In addition to abrupt large faults, the SDF-based algorithms are capable of detecting slowly evolving anomalies (i.e. deviations from the nominal behaviour) based on analysis of time series data of critical process variables of different engine components. The second part, which is a companion paper, validates the concept, laid out in the first part, on the simulation test bed of a generic two-spool turbofan aircraft engine model for detection and isolation of incipient faults.},
	Author = {Gupta, S. and Ray, A. and Sarkar, S. and Yasar, M.},
	Journal = {Proceedings of the Institution of Mechanical Engineers Part G-Journal of Aerospace Engineering},
	Keywords = {aircraft propulsion gas turbine engines fault detection and isolation statistical pattern recognition time-series analysis anomaly detection fatigue damage systems},
	Number = {G3},
	Pages = {307-318},
	Title = {Fault detection and isolation in aircraft gas turbine engines. {P}art 1: underlying concept},
	Volume = {222},
	Year = {2008}}

@article{AD:Hodge2004SurveyOfOD,
	Abstract = {Outlier detection has been used for centuries to detect and, where appropriate, remove anomalous observations from data. Outliers arise due to mechanical faults, changes in system behaviour, fraudulent behaviour, human error, instrument error or simply through natural deviations in populations. Their detection can identify system faults and fraud before they escalate with potentially catastrophic consequences. It can identify errors and remove their contaminating effect on the data set and as such to purify the data for processing. The original outlier detection methods were arbitrary but now, principled and systematic techniques are used, drawn from the full gamut of Computer Science and Statistics. In this paper, we introduce a survey of contemporary techniques for outlier detection. We identify their respective motivations and distinguish their advantages and disadvantages in a comparative review.},
	Author = {Hodge, V. J. and Austin, J.},
	Journal = {Artificial Intelligence Review},
	Keywords = {anomaly detection deviation noise novelty outlier recognition novelty detection},
	Number = {2},
	Pages = {85-126},
	Title = {A survey of outlier detection methodologies},
	Volume = {22},
	Year = {2004}}

@incollection{PCA:Hotelling1947MQC,
	Address = {New York; London},
	Author = {Hotelling, H.},
	Booktitle = {Selected Techniques of Statistical Analysis for Scientific and Industrial Research and Production and Management Engineering},
	Date-Modified = {2011-09-26 18:40:14 +0100},
	Editor = {Eisenhart, Churchill and Hastay, M.W. and Wallis, W.A.},
	Keywords = {principal component analysis},
	Pages = {111-184},
	Publisher = {Mc{G}raw--{H}ill},
	Title = {Multivariate Quality Control, Illustrated by the Air Testing of Sample Bombsights},
	Year = {1947}}

@article{ICA:Hyvarinen1999FastICA,
	Abstract = {Independent component analysis (ICA) is a statistical method for transforming an observed multidimensional random vector into components that are statistically as independent from each other as possible. In this paper, we use a combination of two different approaches for linear ICA: Comon's information-theoretic approach and the projection pursuit approach. Using maximum entropy approximations of differential entropy, we introduce a family of new contrast (objective) functions for ICA. These contrast functions enable both the estimation of the whole decomposition by minimizing mutual information, and estimation of individual independent components as projection pursuit directions, The statistical properties of the estimators based on such contrast functions are analyzed under the assumption of the linear mixture model, and it is shown how to choose contrast functions that are robust and/or of minimum variance, Finally, we introduce simple fixed-point algorithms for practical optimization of the contrast functions. These algorithms optimize the contrast functions very fast and reliably.},
	Author = {Hyv\"{a}rinen, A.},
	Journal = {Ieee Transactions on Neural Networks},
	Keywords = {projection pursuit blind separation neural networks natural images extraction artifacts filters},
	Number = {3},
	Pages = {626-634},
	Title = {Fast and robust fixed-point algorithms for independent component analysis},
	Volume = {10},
	Year = {1999}}

@article{ICA:Hyvarinen1999FastRobustICA,
	Abstract = {The author previously introduced a fast fixed-point algorithm for independent component analysis. The algorithm was derived from objective functions motivated by projection pursuit. In this paper, it is shown that the algorithm is closely connected to maximum likelihood estimation as well. The basic fixed-point algorithm maximizes the likelihood under the constraint of decorrelation, if the score function is used as the nonlinearity. Modifications of the algorithm maximize the likelihood without constraints.},
	Author = {Hyv\"{a}rinen, A.},
	Date-Modified = {2011-05-24 15:52:02 +0100},
	Journal = {Neural Processing Letters},
	Keywords = {independent component analysis, blind source separation, maximum likelihood blind separation},
	Number = {1},
	Pages = {1-5},
	Title = {The fixed-point algorithm and maximum likelihood estimation for independent component analysis},
	Volume = {10},
	Year = {1999}}

@article{ICA:Hyvarinen1997FastICA,
	Abstract = {We introduce a novel fast algorithm for independent component analysis, which can be used for blind source separation and feature extraction. We show how a neural network learning rule can be transformed into a fixed-point iteration, which provides an algorithm that is very simple, does not depend on any user-defined parameters, and is fast to converge to the most accurate solution allowed by the data. The algorithm finds, one at a time, all nongaussian independent components, regardless of their probability distributions. The computations can be performed in either batch mode or a semiadaptive manner. The convergence of the algorithm is rigorously proved, and the convergence speed is shown to be cubic. Some comparisons to gradient-based algorithms are made, showing that the new algorithm is usually 10 to 100 times faster, sometimes giving the solution in just a few iterations.},
	Author = {Hyv\"{a}rinen, A. and Oja, E.},
	Journal = {Neural Computation},
	Keywords = {blind separation deconvolution},
	Number = {7},
	Pages = {1483-1492},
	Title = {A fast fixed-point algorithm for independent component analysis},
	Volume = {9},
	Year = {1997}}

@article{ICA:Hyvarinen2000ICAAlgorithms,
	Abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so thar the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject. (C) 2000 Published by Elsevier Science Ltd.},
	Author = {Hyv\"{a}rinen, A. and Oja, E.},
	Date-Modified = {2011-05-24 15:53:14 +0100},
	Journal = {Neural Networks},
	Keywords = {independent component analysis, projection pursuit, blind signal separation, source separation, factor analysis representation, maximum-likelihood-estimation blind source separation, fixed-point algorithm, projection pursuit, neural networks, sparse code identification, shrinkage artifacts infomax},
	Number = {4-5},
	Pages = {411-430},
	Title = {Independent component analysis: algorithms and applications},
	Volume = {13},
	Year = {2000}}

@book{ICA:Hyvarinen2001ICA00,
	Address = {New York; Chichester},
	Author = {Hyv\"{a}rinen, Aapo and Karhunen, Juha and Oja, Erkki},
	Date-Modified = {2011-09-26 19:27:07 +0100},
	Keywords = {independent component analysis},
	Publisher = {John Wiley \& Sons},
	Title = {Independent component analysis},
	Year = {2001}}

@techreport{DJPhD2nd,
	Author = {Jiang, Dazhi},
	Title = {A Further Investigation of Data-driven Fault Diagnosis Methods for Power Plant Novelty Detection \& Beater Wheal Mill Data Preview - The 2nd Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2007}}

@techreport{DJPhD3rd,
	Author = {Jiang, Dazhi},
	Title = {An Introduction to Independent Component Analysis and its Applications for Fault Detection \& A Discussion of Quantization Error Calculation in {NDT} - The 3rd Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2007}}

@techreport{DJPhD1st,
	Author = {Jiang, Dazhi},
	Title = {A Study of Data-Mining Methodologies for Power Plant Anomaly Detection - The 1st Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2007}}

@techreport{DJPhD5th,
	Author = {Jiang, Dazhi},
	Title = {Independent Component Analysis and its Application to {West Windsor} Data \& {GCE}-based Kernel Density Estimation - The 5th Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2008}}

@techreport{DJPhD4th,
	Author = {Jiang, Dazhi},
	Title = {Kernel Density Estimation and its Application to {West Windsor} Data - The 4th Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2008}}

@techreport{DJPhD6th,
	Author = {Jiang, Dazhi},
	Title = {Independent Component Analysis and its Application to {West Windsor} Data - The 6th Progress Report on {PhD} Programme: Optimal Data-Mining Methodologies for Power Plant Anomaly Detection},
	Year = {2009}}

@article{KDE:Jones1990Performance,
	Author = {Jones, M. C.},
	Journal = {Statistics \& Probability Letters},
	Number = {2},
	Pages = {129-132},
	Title = {The Performance of Kernel Density-Functions in Kernel Distribution Function Estimation},
	Volume = {9},
	Year = {1990}}

@article{ICA:Jutten1991BSSI,
	Abstract = {The separation of independent sources from an array of sensors is a classical but difficult problem in signal processing.  Based on some biological observations, an adaptive algorithm is proposed to separate simultaneously all the unknown independent sources.  The adaptive rule, which constitutes an independence test using non-linear functions, is the main original point of this blind identification procedure.  Moreover, a new concept, that of INdependent Components Analysis (INCA), more powerful than the classical Principal Components Analysis (in decision tasks) emerges from this work.},
	Author = {Jutten, C. and Herault, J.},
	Journal = {Signal Processing},
	Keywords = {separation of sources high order moments principal components independent components neural networks linear recursive adaptive filter},
	Number = {1},
	Pages = {1-10},
	Title = {Blind Separation of Sources, {P}art {I}: {A}n Adaptive Algorithm Based on Neuromimetic Architecture},
	Volume = {24},
	Year = {1991}}

@article{SA:Kirkpatrick1983OptimizationbySA,
	Author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
	Journal = {Science},
	Number = {4598},
	Pages = {671-680},
	Title = {Optimization by Simulated Annealing},
	Volume = {220},
	Year = {1983}}

@book{PDE:Larsson2003Partial,
	Address = {Berlin, Heidelberg},
	Author = {Larsson, Stig and Thomee, Vidar},
	Publisher = {Springer-Verlag},
	Title = {Partial Differential Equations with Numerical Methods},
	Year = {2003}}

@phdthesis{SOM:Lee2002AnomalyDetection,
	Author = {Lee, Daithi Norman},
	School = {UMIST},
	Title = {Investigation and application anomaly detection for industrial gas turbine data},
	Type = {Ph{D} Thesis},
	Year = {2002}}

@article{ICA:Lee2004StatiscalDynamic,
	Abstract = {Most multivariate statistical monitoring methods based on principal component analysis (PCA) assume implicitly that the observations at one time are statistically independent of observations at past time and the latent variables follow a Gaussian distribution. However, in real chemical and biological processes, these assumptions are invalid because of their dynamic and nonlinear characteristics. Therefore, monitoring charts based on conventional PCA tend to show many false alarms and bad delectability. In this paper, a new statistical process monitoring method using dynamic independent component analysis (DICA) is proposed to overcome these disadvantages. ICA is a recently developed technique for revealing hidden factors that underlies sets of measurements followed on a non-Gaussian distribution. Its goal is to decompose a set of multivariate data into a base of statistically independent components without a loss of information. The proposed DICA monitoring method is applying ICA to the augmenting matrix with time-lagged variables. DICA can show more powerful monitoring performance in the case of a dynamic process since it can extract source signals which are independent of the auto- and cross-correlation of variables. It is applied to fault detection in both a simple multivariate dynamic process and the Tennessee Eastman process. The simulation results clearly show that the method effectively detects faults in a multivariate dynamic process. (C) 2004 Elsevier Ltd. All rights reserved.},
	Author = {Lee, J. M. and Yoo, C. and Lee, I. B.},
	Journal = {Chemical Engineering Science},
	Keywords = {process monitoring fault detection independent component analysis (ica) principal component analysis (pca) process control systems engineering fault-detection diagnosis pca performance models algorithms},
	Number = {14},
	Pages = {2995-3006},
	Title = {Statistical monitoring of dynamic processes based on dynamic independent component analysis},
	Volume = {59},
	Year = {2004}}

@article{ICA:Lee2004Statiscal,
	Abstract = {In this paper we propose a new statistical method for process monitoring that uses independent component analysis (ICA). ICA is a recently developed method in which the goal is to decompose observed data into linear combinations of statistically independent components [1,2]. Such a representation has been shown to capture the essential structure of the data in many applications, including signal separation and feature extraction. The basic idea of our approach is to use ICA to extract the essential independent components that drive a process and to combine them with process monitoring techniques. I-2, I-e(2) and SPE charts are proposed as on-line monitoring charts and contribution plots of these statistical quantities are also considered for fault identification. The proposed monitoring method was applied to fault detection and identification in both a simple multivariate process and the simulation benchmark of the biological wastewater treatment process, which is characterized by a variety of fault sources with non-Gaussian characteristics. The simulation results clearly show the power and advantages of ICA monitoring in comparison to PCA monitoring. (C) 2003 Elsevier Ltd. All rights reserved.},
	Author = {Lee, J. M. and Yoo, C. K. and Lee, I. B.},
	Journal = {Journal of Process Control},
	Keywords = {process monitoring fault detection independent component analysis kernel density estimation wastewater treatment process disturbance detection contribution plots fault-detection algorithms diagnosis pca},
	Number = {5},
	Pages = {467-485},
	Title = {Statistical process monitoring with independent component analysis},
	Volume = {14},
	Year = {2004}}

@article{AD:Markou2003NoveltyDetectionA,
	Abstract = {Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. Novelty detection is one of the fundamental requirements of a good classification or identification system since sometimes the test data contains information about objects that were not known at the time of training the model. In this paper we provide state-of-the-art review in the area of novelty detection based on statistical approaches. The second part paper details novelty detection using neural networks. As discussed, there are a multitude of applications where novelty detection is extremely important including signal processing, computer vision, pattern recognition, data mining, and robotics. (C) 2003 Elsevier B.V. All rights reserved.},
	Author = {Markou, Markos and Singh, Singh},
	Journal = {Signal Processing},
	Keywords = {novelty detection review statistical approaches gaussian mixture models hidden markov models knn parzen density estimation string matching clustering reject option classification outliers network system},
	Number = {12},
	Pages = {2481-2497},
	Title = {Novelty detection: a review - part 1: statistical approaches},
	Volume = {83},
	Year = {2003}}

@article{AD:Markou2003NoveltyDetectionB,
	Abstract = {Novelty detection is the identification of new or unknown data or signal that a machine learning system is not aware of during training. In this paper we focus on neural network-based approaches for novelty detection. Statistical approaches are covered in Part 1 paper. (C) 2003 Elsevier B.V. All rights reserved.},
	Author = {Markou, Markos and Singh, Singh},
	Journal = {Signal Processing},
	Keywords = {novelty detection network-based approaches mlp art rbf neural networks density-estimation classification memory classifiers performance},
	Number = {12},
	Pages = {2499-2521},
	Title = {Novelty detection: a review - part 2: neural network based approaches},
	Volume = {83},
	Year = {2003}}

@article{CR:Martin1996Nonparametric,
	Abstract = {Statistical Process Control (SPC) provides a tool for achieving and maintaining product quality. In today's climate of major data monitoring campaigns there has been an increase in interest in the multivariate statistical projection techniques of principal components analysis and projection to latent structures for process performance monitoring. Within univariate SPC, techniques for identifying when a process is moving out of control are well established. Similar guidelines are required for multivariate statistical process control (MSPC). Two approaches will be discussed - Hotelling's T-2 statistic and a new approach, the M(2) statistic. Both approaches will be illustrated by application to a high pressure low density polyethylene tubular reactor and to a batch methyl methacrylate polymerisation reactor. Copyright (C) 1996 Elsevier Science Ltd},
	Author = {Martin, E. B. and Morris, A. J.},
	Journal = {Journal of Process Control},
	Keywords = {multivariate statistical process control fault detection and diagnosis confidence bounds},
	Number = {6},
	Pages = {349-358},
	Title = {Non-parametric confidence bounds for process performance monitoring charts},
	Volume = {6},
	Year = {1996}}

@article{AD4PP:McArthur2005AgentBased,
	Abstract = {Online diagnostics and online condition monitoring are important functions within the operation and maintenance of a power plant. When there is knowledge of the relationships between the raw data and the underlying phenomena within the plant item, typical intelligent system-based interpretation algorithms can be implemented. Increasingly, health data is captured without any underlying knowledge concerning the link between the data and their relationship to physical and electrical phenomena within the plant item. This leads to the requirement for dynamic and learning condition monitoring systems that are able to determine the expected and normal plant behavior over time. This paper describes how multi-agent system technology can be used as the underpinning platform for such condition monitoring systems. This is demonstrated through a prototype multi-agent anomaly detection system applied to a 2.5-MW diesel engine driven alternator system.},
	Author = {McArthur, S. D. J. and Booth, C. D. and McDonald, J. R. and McFadyen, I. T.},
	Journal = {Ieee Transactions on Power Systems},
	Keywords = {cooperative systems decision support systems generators intelligent systems monitoring multi-agent systems},
	Number = {4},
	Pages = {1675-1682},
	Title = {An agent-based anomaly detection architecture for condition monitoring},
	Volume = {20},
	Year = {2005}}

@inproceedings{PCA:Niu2005RBFPCA,
	Abstract = {Recognizing the shortcomings of the traditional principal component analysis (PCA) used in fault detection of the nonlinear process, a nonlinear PCA (NLPCA) method based on radial basis function (RBF) neural networks is developed for fault detection. Firstly, a NLPCA model composing two RBF networks is proposed where the first network achieves the nonlinear transformation of the input variables to principal component and the second network performs the inverse transformation to reproducing the original data. Secondly, the principal curves algorithm is used to resolve the acquirement of the training data. Finally, the fault detection method using the RBF networks-based NLPCA is presented and then the validity of the proposed approach is illustrated by a simulation example of a 3-order nonlinear system. ?2005 IEEE.},
	Address = {Guangzhou, China},
	Author = {Niu, Zheng and Liu, Ji Zhen and Niu, Yu Guang},
	Booktitle = {2005 International Conference on Machine Learning and Cybernetics},
	Keywords = {Fault detection Nonlinear principal component analysis Principal curves Radial basis function neural network Algorithms Mathematical transformations Nonlinear control systems Principal component analysis Fault detection Principal curves Nonlinear systems},
	Pages = {4784-4788},
	Series = {International Conference on Machine Learning and Cybernetics, ICMLC 2005},
	Title = {{RBF} networks-based nonlinear principal component analysis for process fault detection},
	Year = {2005}}

@inproceedings{PCA:Niu2005ReformativePCA,
	Abstract = {Because the operating condition changes frequently, it's difficult to describe the statistical property of the power plant process with single principal component model (PCM). So the application of traditional PCA-based fault detection method can bring many misdiagnoses. A reformative PCA-based fault detection method suitable for power plant process is proposed. First K-mean cluster analysis is used to classify the process data and obtain the data sets under the various stable operating condition. Then the PCM group is established using the classified data sets to describe the entire process. Finally the detecting sample is carried on fuzzy partition during fault detecting and the PCM suitable for current operating condition is dynamically calculated and used for fault detection. The field data is used to contrast the application of traditional method with reformative method in the fault detection of boiler process. The results indicate that the reformative method can adapt the operating condition change, reduce the misdiagnosis and enhance the detection sensitivity. ?2005 IEEE.},
	Address = {Guangzhou, China},
	Author = {Niu, Zheng and Liu, Ji Zhen and Niu, Yu Guang and Pan, Yu Song},
	Booktitle = {2005 International Conference on Machine Learning and Cybernetics},
	Keywords = {Fault detection Fuzzy partition K-means cluster analysis Power plant process Principal component analysis (PCA) Boilers Principal component analysis Fault detection Fuzzy partition K-means cluster analysis Power plants},
	Pages = {2133-2138},
	Series = {International Conference on Machine Learning and Cybernetics, ICMLC 2005},
	Title = {A reformative {PCA}-based fault detection method suitable for power plant process},
	Year = {2005}}

@misc{ANN:Palme2008GasMscThesis,
	Author = {Palm\'e, Thomas},
	Publisher = {Lund University, Sweden},
	Title = {Gas Turbine Modelling for Degradation Tracking and Monitoring with Artificial Neural Networks},
	Volume = {MSc thesis},
	Year = {2008}}

@article{Stretching:Parsopoulos2001Ojective,
	Abstract = {This paper introduces a new technique for the alleviation of local minima in minimization problems. The proposed "stretching" technique transforms the objective function by stretching upwards the neighborhood of a given point, and assists in eliminating local minima, while preserving the global ones. Experiments indicate that when a global search method converges to an undesired local minimum, the use of the new technique provides a way of escape and helps convergence to the global minimum.},
	Author = {Parsopoulos, K. E. and Plagianakos, V. P. and Magoulas, G. D. and Vrahatis, M. N.},
	Journal = {Nonlinear Analysis-Theory Methods \& Applications},
	Number = {5},
	Pages = {3419-3424},
	Title = {Objective function ``stretching'' to alleviate convergence to local minima},
	Volume = {47},
	Year = {2001}}

@article{KDE:Parzen1962OnEstimation,
	Author = {Parzen, Emanuel},
	Journal = {The Annals of Mathematical Statistics},
	Number = {3},
	Pages = {1065-1076},
	Title = {On Estimation of a Probability Density Function and Mode},
	Volume = {33},
	Year = {1962}}

@article{AD:Patcha2007OverviewOfAD,
	Abstract = {As advances in networking technology help to connect the distant corners of the globe and as the Internet continues to expand its influence as a medium for communications and commerce, the threat from spammers, attackers and criminal enterprises has also grown accordingly. It is the prevalence of such threats that has made intrusion detection systems-the cyberspace's equivalent to the burglar alarm join ranks with firewalls as one of the fundamental technologies for network security. However, today's commercially available intrusion detection systems are predominantly signature-based intrusion detection systems that are designed to detect known attacks by utilizing the signatures of those attacks. Such systems require frequent rule-base updates and signature updates, and are not capable of detecting unknown attacks. In contrast, anomaly detection systems, a subset of intrusion detection systems, model the normal system/network behavior which enables them to be extremely effective in finding and foiling both known as well as unknown or "zero day" attacks. While anomaly detection systems are attractive conceptually, a host of technological problems need to be overcome before they can be widely adopted. These problems include: high false alarm rate, failure to scale to gigabit speeds, etc. In this paper, we provide a comprehensive survey of anomaly detection systems and hybrid intrusion detection systems of the recent past and present. We also discuss recent technological trends in anomaly detection and identify open problems and challenges in this area. (c) 2007 Elsevier B.V. All rights reserved.},
	Author = {Patcha, A. and Park, J. M.},
	Journal = {Computer Networks},
	Keywords = {survey anomaly detection machine learning statistical anomaly detection data mining intrusion-detection models networks},
	Number = {12},
	Pages = {3448-3470},
	Title = {An overview of anomaly detection techniques: {E}xisting solutions and latest technological trends},
	Volume = {51},
	Year = {2007}}

@article{PCA:Pearson1901OnLines,
	Author = {Pearson, K.},
	Date-Modified = {2011-09-26 18:40:14 +0100},
	Journal = {Philosophical Magazine},
	Keywords = {principal component analysis},
	Number = {6},
	Pages = {559-572},
	Title = {On lines and planes of closest fit to systems of points in space},
	Volume = {2},
	Year = {1901}}

@article{CRDLS:Polonik1995DensityLevelSets,
	Abstract = {By using empirical process theory, the so-called excess mass approach is studied. It can be applied to various statistical problems, especially in higher dimensions, such as testing for multimodality, estimating density contour clusters, estimating nonlinear functionals of a density, density estimation, regression problems and spectral analysis. We mainly consider the problems of testing for multimodality and estimating density contour clusters, but the other problems also are discussed. The excess mass (over C) is defined as a supremum of a certain functional defined on C, where C is a class of subsets of the d-dimensional Euclidean space. Comparing excess masses over different classes C yields information about the modality of the underlying probability measure F. This can be used to construct tests for multimodality. If F has a density f, the maximizing sets of the excess mass are level sets or density contour clusters of f, provided they he in C. The excess mass and the density contour clusters can be estimated from the data. Asymptotic properties of these estimators and of the test statistics are studied for general classes C, including the classes of balls, ellipsoids and convex sets.},
	Author = {Polonik, W.},
	Journal = {Annals of Statistics},
	Keywords = {excess mass density contour cluster level set estimation multimodality empirical process theory support estimation convex hull central limit-theorem partial-sum processes iterated logarithm variance sets law},
	Number = {3},
	Pages = {855-881},
	Title = {Measuring Mass Concentrations and Estimating Density Contour Clusters - an Excess Mass Approach},
	Volume = {23},
	Year = {1995}}

@book{ICA:Roberts2001ICAPrinciples,
	Author = {Roberts, Stephen and Everson, Richard},
	Date-Modified = {2011-09-26 18:14:46 +0100},
	Keywords = {independent component analysis},
	Publisher = {Cambridge University Press},
	Title = {Independent Component Analysis: Principles and Practice},
	Year = {2001}}

@book{GT:Saravanamuttoo2009GTT,
	Address = {Harlow},
	Author = {Saravanamuttoo, H.I.H. and Rogers, Gordon and Cohen, Henry and Straznicky, Paul},
	Edition = {6th},
	Publisher = {{Pearson Education Ltd.}},
	Title = {Gas Turbine Theory},
	Year = {2009}}

@article{FDI:Sarkar2008FDIInAGTB,
	Abstract = {The first part of this two-part paper, which is a companion paper, has developed a novel concept of fault detection and isolation (FDI) in aircraft gas turbine engines. The FDI algorithms are built upon the statistical pattern recognition method of symbolic dynamic filtering (SDF) that is especially suited for real-time detection and isolation of slowly evolving anomalies in engine components, in addition to abrupt faults. The FDI methodology is based on the analysis of time series data of available sensors and/or analytically derived variables in the gas path dynamics.
The current paper, which is the second of two parts, validates the algorithms of FDI, formulated in the first part, on a simulation test bed. The test bed is built upon an integrated model of a generic two-spool turbofan aircraft gas turbine engine including the engine control system.},
	Author = {Sarkar, S. and Yasar, M. and Gupta, S. and Ray, A. and Mukherjee, K.},
	Journal = {Proceedings of the Institution of Mechanical Engineers Part G-Journal of Aerospace Engineering},
	Keywords = {aircraft gas turbine engines fault detection and isolation symbolic dynamic filtering time-series analysis systems},
	Number = {G3},
	Pages = {319-330},
	Title = {Fault detection and isolation in aircraft gas turbine engines. {P}art 2: validation on a simulation test bed},
	Volume = {222},
	Year = {2008}}

@book{SVM:Scholkopf2001Learning,
	Abstract = {In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs?kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics.<br /> <br /> <i>Learning with Kernels</i> provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.},
	Author = {Sch\"{o}lkopf, Bernhard and Smola, Alexander},
	Keywords = {kernel-method learning-theory machine-learning pattern-recognition},
	Publisher = {The MIT Press},
	Title = {{Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond (Adaptive Computation and Machine Learning)}},
	Year = {2001}}

@article{KDE:Sheather1991AReliableAMISE,
	Abstract = {We present a new method for data-based selection of the bandwidth in kernel density estimation which has excellent properties.  It improves on a recent procedure of Park and Marron (which itself is a good method) in various ways.  First, the new method has superior theoretical performance; second, it also has a computational advantage; third, the new method has reliably good performance for smooth densities in simulations, performance that is second to none in the existing literature.  These methods are based on choosing the bandwidth to (approximately) minimize good quality estimates of the mean integrated squared error.  The key to the success of the current procedure is the reintroduction of a nonstochastic term which was previously omitted together with use of the bandwidth to reduce bias in estimation without inflating variance.},
	Author = {Sheather, S. J. and Jones, M. C.},
	Journal = {Journal of the Royal Statistical Society Series B-Methodological},
	Keywords = {adaptive choice bias reduction functional estimation smoothing squared error loss functions data-based algorithm window width point},
	Number = {3},
	Pages = {683-690},
	Title = {A Reliable Data-Based Bandwidth Selection Method for Kernel Density-Estimation},
	Volume = {53},
	Year = {1991}}

@book{DE:Silverman1986Density,
	Address = {London, UK},
	Author = {Silverman, B.W.},
	Publisher = {Chapman \& Hall},
	Title = {Density estimation for statistics and data analysis},
	Year = {1986}}

@article{AD:Steinwart2005ClassificationFramework,
	Abstract = {One way to describe anomalies is by saying that anomalies are not concentrated. This leads to the problem of finding level sets for the data generating density. We interpret this learning problem as a binary classification problem and compare the corresponding classification risk with the standard performance measure for the density level problem. In particular it turns out that the empirical classification risk can serve as an empirical performance measure for the anomaly detection problem. This allows us to compare different anomaly detection algorithms empirically, i. e. with the help of a test set. Furthermore, by the above interpretation we can give a strong justification for the well-known heuristic of artificially sampling "labeled" samples, provided that the sampling plan is well chosen. In particular this enables us to propose a support vector machine (SVM) for anomaly detection for which we can easily establish universal consistency. Finally, we report some experiments which compare our SVM to other commonly used methods including the standard one-class SVM.},
	Author = {Steinwart, I. and Hush, D. and Scovel, C.},
	Journal = {Journal of Machine Learning Research},
	Keywords = {unsupervised learning anomaly detection density levels classification svms novelty detection density-estimation support classifiers contour},
	Pages = {211-232},
	Title = {A classification framework for anomaly detection},
	Volume = {6},
	Year = {2005}}

@article{CRDLS:Tsybakov1997DensityLevelSets,
	Abstract = {Let X-1,...,X-n be independent identically distributed observations from an unknown probability density f((.)). Consider the problem of estimating the level set G = G(f)(lambda)= (x epsilon R-2: f(x) greater than or equal to lambda) from the sample X-1,...,X-n, under the assumption that the boundary of G has a certain smoothness. We propose piecewise-polynomial estimators of G based on the maximization of local empirical excess masses. We show that the estimators have optimal rates of convergence in the asymptotically minimax sense within the studied classes of densities. We find also the optimal convergence rates for estimation of convex level sets. A generalization to the N-dimensional case, where N > 2, is given.},
	Author = {Tsybakov, A. B.},
	Journal = {Annals of Statistics},
	Keywords = {density level set excess mass shape function optimal rate of convergence piecewise-polynomial estimator boundaries contour},
	Number = {3},
	Pages = {948-969},
	Title = {On nonparametric estimation of density level sets},
	Volume = {25},
	Year = {1997}}

@article{FDD:Venkatasubramanian2003ReviewII,
	Abstract = {In this part of the paper, we review qualitative model representations and search strategies used in fault diagnostic systems. Qualitative models are usually developed based on some fundamental understanding of the physics and chemistry of the process. Various forms of qualitative models such as causal models and abstraction hierarchies are discussed. The relative advantages and disadvantages of these representations are highlighted. In terms of search strategies, we broadly classify them as topographic and symptomatic search techniques. Topographic searches perform malfunction analysis using a template of normal operation, whereas, symptomatic searches look for symptoms to direct the search to the fault location. Various forms of topographic and symptomatic search strategies are discussed. (C) 2002 Published by Elsevier Science Ltd.},
	Author = {Venkatasubramanian, V. and Rengaswamy, R. and Kavuri, S. N.},
	Journal = {Computers and Chemical Engineering},
	Keywords = {symptomatic search topographic search signed directed graph probabilistic causal model cause-effect digraph chemical process process plants qualitative simulation system failures 1st principles expert systems fuzzy-logic},
	Number = {3},
	Pages = {313-326},
	Title = {A review of process fault detection and diagnosis {P}art {II}: {Q}uantitative model and search strategies},
	Volume = {27},
	Year = {2003}}

@article{FDD:Venkatasubramanian2003ReviewIII,
	Abstract = {In this final part, we discuss fault diagnosis methods that are based on historic process knowledge. We also compare and evaluate the various methodologies reviewed in this series in terms of the set of desirable characteristics we proposed in Part I. This comparative study reveals the relative strengths and weaknesses of the different approaches. One realizes that no single method has all the desirable features one would like a diagnostic system to possess. It is our view that some of these methods can complement one another resulting in better diagnostic systems. Integrating these complementary features is one way to develop hybrid systems that could overcome the limitations of individual solution strategies. The important role of fault diagnosis in the broader context of process operations is also outlined. We also discuss the technical challenges in research and development that need to be addressed for the successful design and implementation of practical intelligent supervisory control systems for the process industries. (C) 2002 Published by Elsevier Science Ltd.},
	Author = {Venkatasubramanian, V. and Rengaswamy, R. and Kavuri, S. N. and Yin, K.},
	Journal = {Computers and Chemical Engineering},
	Keywords = {supervisory control diagnosis hybrid system artificial neural networks principal component analysis pattern-recognition approach chemical processes dynamic-systems sensor network expert-system comprehensive design reliability criteria framework},
	Number = {3},
	Pages = {327-346},
	Title = {A review of process fault detection and diagnosis {P}art {III}: {P}rocess history based methods},
	Volume = {27},
	Year = {2003}}

@article{FDD:Venkatasubramanian2003ReviewI,
	Abstract = {Fault detection and diagnosis is an important problem in process engineering. It is the central component of abnormal event management (AEM) which has attracted a lot of attention recently. AEM deals with the timely detection, diagnosis and correction of abnormal conditions of faults in a process. Early detection and diagnosis of process faults while the plant is still operating in a controllable region can help avoid abnormal event progression and reduce productivity loss. Since the petrochemical industries lose an estimated 20 billion dollars every year, they have rated AEM as their number one problem that needs to be solved. Hence, there is considerable interest in this field now from industrial practitioners as well as academic researchers, as opposed to a decade or so ago. There is an abundance of literature on process fault diagnosis ranging from analytical methods to artificial intelligence and statistical approaches. From a modelling perspective, there are methods that require accurate process models, semi-quantitative models, or qualitative models. At the other end of the spectrum, there are methods that do not assume any form of model information and rely only on historic process data. In addition, given the process knowledge, there are different search techniques that can be applied to perform diagnosis. Such a collection of bewildering array of methodologies and alternatives often poses a difficult challenge to any aspirant who is not a specialist in these techniques. Some of these ideas seem so far apart from one another that a non-expert researcher or practitioner is often left wondering about the suitability of a method for his or her diagnostic situation. While there have been some excellent reviews in this field in the past, they often focused on a particular branch, such as analytical models, of this broad discipline. The basic aim of this three part series of papers is to provide a systematic and comparative study of various diagnostic methods from different perspectives. We broadly classify fault diagnosis methods into three general categories and review them in three parts. They are quantitative model-based methods, qualitative model-based methods, and process history based methods. In the first part of the series, the problem of fault diagnosis is introduced and approaches based on quantitative models are reviewed. In the remaining two parts, methods based on qualitative models and process history data are reviewed. Furthermore, these disparate methods will be compared and evaluated based on a common set of criteria introduced in the first part of the series. We conclude the series with a discussion on the relationship of fault diagnosis to other process operations and on emerging trends such as hybrid blackboard-based frameworks for fault diagnosis. (C) 2002 Published by Elsevier Science Ltd.},
	Author = {Venkatasubramanian, V. and Rengaswamy, R. and Yin, K. and Kavuri, S. N.},
	Journal = {Computers and Chemical Engineering},
	Keywords = {fault detection diagnosis process safety knowledge-based redundancy linear chemical processes failure-detection dynamic-systems design},
	Number = {3},
	Pages = {293-311},
	Title = {A review of process fault detection and diagnosis {P}art {I}: {Q}uantitative model-based methods},
	Volume = {27},
	Year = {2003}}

@book{GT:Walsh2004GTP,
	Address = {Oxford},
	Author = {Walsh, Philip P. and Fletcher, Paul},
	Edition = {2nd},
	Publisher = {Blackwell Science},
	Title = {Gas turbine performance},
	Year = {2004}}

@article{SA:Wang2006AnEfficientGRFSA,
	Abstract = {A two stage algorithm, consisting of gradient technique and particle swarm optimization (PSO) method for global optimization is proposed. The gradient method is used to find a local minimum of objective function efficiently, and PSO with potential parallel search is employed to help the minimization sequence to escape from the previously converged local minima to a better point which is then given to the gradient method as a starting point to start a new local search. The above search procedure is applied repeatedly until a global minimum of the objective function is found. In addition, a repulsion technique and partially initializing population method are also incorporated in the new algorithm to increase its global search ability. Global convergence is proven, and tests on benchmark problems show that the proposed method is more effective and reliable than the existing optimization methods.},
	Author = {Wang, Y. J. and Zhang, J. S. and Zhang, Y. F.},
	Journal = {Advances in Machine Learning and Cybernetics},
	Keywords = {minima},
	Pages = {487-496},
	Title = {An effective and efficient two stage algorithm for global optimization},
	Volume = {3930},
	Year = {2006}}

@article{FD-RS:Yang2004FaultDiagnosis,
	Abstract = {This paper proposes a new approach to diagnose frequent faults for large-scale equipments in thermal power plants. Based on the acquired data in SCADA (Supervisory control and data acquisition) systems, a hybrid-intelligence data-mining framework is an algorithm in finding minimum size reduction which is based on rough set approach, which makes it possible to eliminate additional test or experiments for fault diagnosis which are usually expensive and involve some risks to the equipment. This approach is also tested by all the data in a SCADA system's database of a thermal power plant for boilers fault diagnosis. The decision rules' accuracy varied from 92 percent to 95 percent in different months.},
	Author = {Yang, Ping and Liu, Sui-sheng and Zhang, Hao},
	Journal = {Control Theory and Applications},
	Keywords = {fault diagnosis data mining rough set attribute reduction decision tree},
	Number = {6},
	Pages = {927-931},
	Title = {Fault diagnosis for large-scale equipment in thermal power plant by data mining},
	Volume = {21},
	Year = {2004}}

@article{SA:Yiu2008AHybridGSA,
	Abstract = {In this paper, a hybrid descent method, consisting of a simulated annealing algorithm and a gradient-based method, is proposed. The simulated annealing algorithm is used to locate descent points for previously converged local minima. The combined method has the descent property and the convergence is monotonic. To demonstrate the effectiveness of the proposed hybrid descent method, several multi-dimensional non-convex optimization problems are solved. Numerical examples show that global minimum can be sought via this hybrid descent method.},
	Author = {Yiu, K. F. C. and Liu, Y. and Teo, K. L.},
	Journal = {Journal of Global Optimization},
	Keywords = {descent method global minimum simulating annealing filled function-method tunneling algorithm minimization trust},
	Number = {2},
	Pages = {229-238},
	Title = {A hybrid descent method for global optimization},
	Volume = {28},
	Year = {2004}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Chap01</string>
		<key>keys</key>
		<string></string>
	</dict>
	<dict>
		<key>group name</key>
		<string>Chap02</string>
		<key>keys</key>
		<string>PCA:Emigholz2006AssumptionsPatent,PCA:Li2000AdaptivePCA,PCA:Bakshi1998MSPCA</string>
	</dict>
</array>
</plist>
}}
